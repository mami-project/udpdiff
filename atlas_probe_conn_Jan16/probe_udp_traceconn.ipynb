{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UDP Traceroute Connectivity by Probe\n",
    "\n",
    "This notebook uses _existing_ RIPE Atlas measurements to determine how many RIPE Atlas probes might have issues with UDP connectivity. The basic methodology is as follows:\n",
    "\n",
    "- Examine measurement metadata to find UDP traceroutes from many probes, over time (currently measurements ending in 2015, or still ongoing).\n",
    "- Take latency to target and target reachability information from each sample. For samples where the target is not reached but some hops did respond, take the latest hop.\n",
    "- Group reachability information by probe, and classify probes by how confident we are UDP is broken on them.\n",
    "\n",
    "This notebook searches the RIPE atlas measurement metadata archive (available from [ftp.ripe.net](ftp://ftp.ripe.net/atlas/measurements)) for UDP and TCP traceroute measurements, and uses the Atlas API to download measurements and cache them locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preamble\n",
    "\n",
    "Set up the environment and define functions we'll use later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Some jupyter magic to set up the environment correctly\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# thanks for letting me know about your plans but i don't really care\n",
    "import warnings\n",
    "warnings.simplefilter(action = \"ignore\", category = FutureWarning)\n",
    "\n",
    "# things we need, things to make us go\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import warnings\n",
    "import hashlib\n",
    "import requests\n",
    "import os.path\n",
    "import time\n",
    "import calendar\n",
    "import itertools\n",
    "import json\n",
    "\n",
    "# HDF5 store for stashing parsed things\n",
    "store = pd.HDFStore('data_cache/udp_traceconn.h5')\n",
    "\n",
    "##############################################################################\n",
    "# Trace metadata named tuple,\n",
    "# and generator for extracting these from the all-measurements-fjson.txt file.\n",
    "##############################################################################\n",
    "\n",
    "TraceMeta = collections.namedtuple(\"TraceMeta\", \n",
    "                (\"msm_id\", \"af\", \"proto\", \"target\", \n",
    "                 \"start_epoch\", \"stop_epoch\", \"interval\", \"probes\"))\n",
    "\n",
    "def tm_generator(first_start=0, last_start=calendar.timegm(time.gmtime()), skip_lines = 0):\n",
    "    current_time = calendar.timegm(time.gmtime())\n",
    "    \n",
    "    with open(\"data_cache/all-measurements-fjson.txt\") as fjf:\n",
    "        for num, line in enumerate(fjf):\n",
    "            if num < skip_lines:\n",
    "                continue\n",
    "            \n",
    "            mm = json.loads(line)\n",
    "                \n",
    "            if (((mm['type']['id'] == 2) or (mm['type']['id'] == 4)) and\n",
    "                ((mm['status']['id'] == 2) or (mm['status']['id'] == 4)) and\n",
    "                (('protocol' in mm) or ('proto_tcp' in mm)) and\n",
    "                (mm['start_time'] >= first_start) and\n",
    "                (mm['start_time'] < last_start) ):\n",
    "            \n",
    "                    if mm['status']['id'] == 4:\n",
    "                        stop_time = mm['stop_time']\n",
    "                    else:\n",
    "                        stop_time = current_time\n",
    "                    \n",
    "                    if 'proto_tcp' in mm and mm['proto_tcp']:\n",
    "                        proto = 'TCP'\n",
    "                    else:\n",
    "                        proto = mm['protocol']\n",
    "                        \n",
    "                    yield TraceMeta(mm['msm_id'], mm['af'], proto, mm['dst_addr'], \n",
    "                                    mm['start_time'], stop_time, mm['interval'],\n",
    "                                    mm['participant_count'])\n",
    "\n",
    "##############################################################################\n",
    "# MSM retrieval code\n",
    "##############################################################################\n",
    "\n",
    "def get_msm(msm_id, gen, cachedir=None, start=None, stop=None):\n",
    "    \"\"\"\n",
    "    Given an MSM, fetch it from the cache or from the RIPE Atlas API.\n",
    "    Yield each separate result according to the generation function.\n",
    "    \"\"\"\n",
    "    url = \"https://atlas.ripe.net/api/v1/measurement/%u/result/\" % (msm_id,)\n",
    "\n",
    "    params = {\"format\": \"json\"}\n",
    "    if start is not None and stop is not None:\n",
    "        params[\"start\"] = str(start)\n",
    "        params[\"stop\"] = str(stop)\n",
    "    \n",
    "    if cachedir and os.path.isdir(cachedir):\n",
    "        filepath = os.path.join(cachedir, \"measurement\", \"%u.json\" % (msm_id,))\n",
    "\n",
    "        # download if not present\n",
    "        if not os.path.isfile(filepath):\n",
    "            with open(filepath, mode=\"wb\") as file:\n",
    "                print(\"Cache miss, retrieving \"+url)\n",
    "                res = requests.get(url, params=params)\n",
    "\n",
    "                if not res.ok:\n",
    "                    raise \"Atlas measurement API request failed: \"+repr(res.json())\n",
    "                \n",
    "                file.write(res.content)\n",
    "\n",
    "        # then read from cache\n",
    "        with open(filepath) as stream:\n",
    "            yield from gen(json.loads(stream.read()))\n",
    "\n",
    "    else:\n",
    "        # just read from the net\n",
    "        res = requests.get(url, params=params)\n",
    "        yield from gen(json.loads(res.content.decode(\"utf-8\")))\n",
    "\n",
    "##############################################################################\n",
    "# Connectivity sample named tuple,\n",
    "# connectivity sample generator for use with get_msm(),\n",
    "# and dataframe creation function wrapping all of this together\n",
    "##############################################################################\n",
    "\n",
    "TCSample = collections.namedtuple(\"TCSample\",\n",
    "                     (\"msm_id\",\"time\",\"af\",\"proto\",\"pid\",\"sip\",\"dip\",\"reached\",\"hop\",\"rtt\"))\n",
    "\n",
    "def gen_tcs(msm_ary):\n",
    "    for a_res in msm_ary:        \n",
    "        if a_res['type'] == 'traceroute':\n",
    "            if ('result' in a_res):\n",
    "                maxhop = 0\n",
    "                maxhop_ok = False\n",
    "                for hop in a_res['result']:\n",
    "                    if 'result' in hop:\n",
    "                        for pkt in hop['result']:\n",
    "                            if 'from' in pkt:\n",
    "                                maxhop = hop['hop']\n",
    "                                if pkt['from'] == a_res['dst_addr']:\n",
    "                                    maxhop_ok = True\n",
    "                                    if 'rtt' in pkt:\n",
    "                                        rtt = pkt['rtt']\n",
    "                                    else:\n",
    "                                        rtt = -1\n",
    "                                    yield TCSample(a_res['msm_id'],\n",
    "                                           int(a_res['timestamp']), a_res['af'], a_res['proto'],\n",
    "                                           a_res['prb_id'], a_res['src_addr'], a_res['dst_addr'],\n",
    "                                           True, maxhop, rtt)\n",
    "                                    break\n",
    "                if not maxhop_ok:\n",
    "                    try:\n",
    "                        yield TCSample(a_res['msm_id'],\n",
    "                                       int(a_res['timestamp']), a_res['af'], a_res['proto'],\n",
    "                                       a_res['prb_id'], a_res['src_addr'], a_res['dst_addr'],\n",
    "                                       False, maxhop, -1)\n",
    "                    except KeyError:\n",
    "                        # ignore completely broken results\n",
    "                        pass\n",
    "\n",
    "def tcsample_dataframe(msm_ids, cachedir=None, start=None, stop=None, chunksize=1000000):\n",
    "    \"\"\"\n",
    "    Given an iterable of MSMs, create a dataframe of trace connectivity samples.\n",
    "    \"\"\"\n",
    "    \n",
    "    # initialize accumulators\n",
    "    adf = pd.DataFrame([], columns=TCSample._fields)\n",
    "    data = []\n",
    "    \n",
    "    # get individual rows from get_msm\n",
    "    for msm_id in msm_ids:\n",
    "        for tcs in get_msm(msm_id, gen=gen_tcs, \n",
    "                           start=start, stop=stop, \n",
    "                           cachedir=cachedir):\n",
    "            data.append(tcs)\n",
    "            \n",
    "            # Append dataframe to dataframe accumulator if chunking.\n",
    "            if len(data) >= chunksize:\n",
    "                adf = adf.append(pd.DataFrame(data, columns=TCSample._fields), ignore_index=True)\n",
    "                data = []\n",
    "                \n",
    "    # Append final dataframe if non-empty.\n",
    "    if len(data) > 0:\n",
    "        adf = adf.append(pd.DataFrame(data, columns=TCSample._fields), ignore_index=True)\n",
    "\n",
    "    # Counter column for aggregation\n",
    "    adf['n'] = 1\n",
    "    \n",
    "    return adf\n",
    "\n",
    "##############################################################################\n",
    "# Plotting utility function\n",
    "##############################################################################\n",
    "\n",
    "def plot_ecdf(a, **kwargs):\n",
    "    sa = np.sort(a)\n",
    "    yv = np.arange(len(sa))/float(len(sa))\n",
    "    plt.plot(sa, yv, **kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1b, 2b: store/restore preparsed raw dataframes in HDF\n",
    "\n",
    "Do this instead of steps 1 and 2 if not reworking parsing and raw dataframs selection. It's silly fast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Restore pre-parsed dataframes from the store, and re-split them as necessary\n",
    "%time tmdf = store['tmdf']\n",
    "%time tcsdf = store['tcsdf']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: find MSM ids for UDP traceroutes \n",
    "\n",
    "Here we limit ourselves to MSMs run (1) from many probes, to maximize the number of probes we'll see samples from, and (2) ending in 2015 or later, to focus on the recent past. Note that many of these are MSMs we specified ourselves for our TMA paper. Not many people seem to be interested in UDP traceroute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 6s, sys: 6.03 s, total: 5min 12s\n",
      "Wall time: 5min 13s\n"
     ]
    }
   ],
   "source": [
    "# get ALL the traceroutes! (takes about five minutes on Forclaz)\n",
    "tmgen = tm_generator()\n",
    "%time tmdf = pd.DataFrame([m for m in tmgen], columns=TraceMeta._fields)\n",
    "tmgen.close() # generator wraps a file, close it.\n",
    "\n",
    "# estimate sample count\n",
    "tmdf['samples'] = (tmdf['probes'] * (tmdf['stop_epoch'] - tmdf['start_epoch'])) / tmdf['interval']\n",
    "\n",
    "# cast timestamps\n",
    "tmdf['start'] = pd.to_datetime(tmdf['start_epoch'] * 1e9)\n",
    "tmdf['stop'] = pd.to_datetime(tmdf['stop_epoch'] * 1e9)\n",
    "tmdf['duration'] = tmdf['stop'] - tmdf['start']\n",
    "\n",
    "# count msms\n",
    "tmdf['n'] = 1\n",
    "\n",
    "# index by msm\n",
    "tmdf.index = pd.Index(tmdf['msm_id'])\n",
    "del(tmdf['msm_id'])\n",
    "\n",
    "# Dump dataframe into the HDF store\n",
    "store['tmdf'] = tmdf\n",
    "\n",
    "# exclude all measurements ending before 1 Jan 2015, and split by protocol\n",
    "tmdf_udp = tmdf[tmdf['proto'] == 'UDP']\n",
    "tmdf_udp = tmdf_udp[tmdf_udp[\"stop\"] >= \"2015-01-01\"]\n",
    "tmdf_tcp = tmdf[tmdf['proto'] == 'TCP']\n",
    "tmdf_tcp = tmdf_tcp[tmdf_tcp[\"stop\"] >= \"2015-01-01\"]\n",
    "tmdf_icmp = tmdf[tmdf['proto'] == 'TCP']\n",
    "tmdf_icmp = tmdf_icmp[tmdf_icmp[\"stop\"] >= \"2015-01-01\"]\n",
    "\n",
    "# find appropriate MSMs\n",
    "msm_ids = tmdf_udp[tmdf_udp['probes'] >= 64].index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8436"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(msm_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Step 2: Retrieve MSMs and parse them into a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7min, sys: 16.7 s, total: 7min 17s\n",
      "Wall time: 7min 31s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/IPython/core/interactiveshell.py:3066: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block2_values] [items->['proto', 'sip', 'dip', 'reached']]\n",
      "\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    }
   ],
   "source": [
    "%time tcsdf = tcsample_dataframe(msm_ids, cachedir=\"data_cache\", chunksize=100000)\n",
    "store['tcsdf'] = tcsdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: classify probe IDs by UDP reachability \n",
    "\n",
    "First, clean the data: drop all samples from MSMs where no traceroute reached the target (target always down), then all samples from probes with less than n=9 samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "msm_reached_sum = tcsdf.groupby('msm_id')['reached'].sum()\n",
    "bad_target_msm_ids = msm_reached_sum[msm_reached_sum == 0].index\n",
    "tcsdf_target_udp_ok = tcsdf[np.logical_not(tcsdf['msm_id'].isin(bad_target_msm_ids))]\n",
    "pid_sum = tcsdf.groupby('pid')['n'].sum()\n",
    "low_volume_pids = pid_sum[pid_sum < 9].index\n",
    "tcsdf_clean = tcsdf_target_udp_ok[np.logical_not(tcsdf_target_udp_ok['pid'].isin(low_volume_pids))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Headline number: how many probes might block UDP?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82 / 2240 (3.661%)\n"
     ]
    }
   ],
   "source": [
    "reached_by_pid = tcsdf_clean.groupby('pid')['reached'].sum()\n",
    "print (\"%u / %u (%5.3f%%)\" % (len(reached_by_pid[reached_by_pid == 0]),\n",
    "                            len(reached_by_pid),\n",
    "                            100 * len(reached_by_pid[reached_by_pid == 0]) / len(reached_by_pid)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch code\n",
    "\n",
    "Sandbox, dirtpile, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3763"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tcsdf_target_udp_ok.groupby('pid')['reached'].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ecdf(tcsdf.groupby('pid').reached.sum() / tcsdf.groupby('pid').n.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_ecdf(tcsdf[np.logical_not(tcsdf['reached'])]['hop'])\n",
    "plt.xlim(0,32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_ecdf(tcsdf[tcsdf['reached']]['hop'])\n",
    "plot_ecdf(tcsdf[np.logical_not(tcsdf['reached'])]['hop'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
